{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from huggingface_hub import login\n",
    "from transformers import AdamWeightDecay, TFAutoModelForTokenClassification, AutoTokenizer\n",
    "\n",
    "import os \n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from src.preprocess import PrepSystem\n",
    "from src.tag import TagInfo\n",
    "from src.train import check_gpus, get_token\n",
    "\n",
    "from evaluate import evaluator\n",
    "from datasets import load_dataset, DatasetInfo, DatasetDict\n",
    "from evaluate import utils, enable_progress_bar, is_progress_bar_enabled, push_to_hub\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses the [`evaluate` library from huggingface](https://huggingface.co/docs/evaluate/v0.4.0/en/base_evaluator#evaluate-models-on-the-hub) which defaults using the first GPU detected. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:24:34.867448: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:34 INFO     [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2023-12-04 11:24:34.885483: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:34.885731: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "# Check for GPUs\n",
    "check_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Login to huggingface \n",
    "create a .env file with a huggingface access token\n",
    "Example:\n",
    "\n",
    "\n",
    "```shell\n",
    "# .env in root dir\n",
    "HF_TOKEN=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\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /home/snek/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "login(get_token())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate the model, the tokenizer and dataset need to be loaded. \n",
    "The `PrepSystem` class can load, filter, and pre-process the dataset and load the tokenizer. This is useful particularly for experiment B which has a modified dataset since it trains on a limited number of tags. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_checkpoint = \"distilbert-base-uncased\"\n",
    "learning_rate = 2e-5\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=0.0)\n",
    "filter_by_lang = \"en\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70039efcf80a4f9eb950667ffc2db67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e17a9f15e848d399178e2305e2f608",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07b3709f1ae74426b37891e5e41e8cec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:24:52 INFO     Filtered language by en. \n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 32908\n",
      "    })\n",
      "})\n",
      "2023-12-04 11:24:52 INFO     Using the full tagset\n",
      "2023-12-04 11:24:52 INFO     Making sure all labels have sequential IDs. This can happen if a reduced tagset is chosen\n",
      "2023-12-04 11:24:52 INFO     All label ids are sequential, nothing to swap.\n",
      "2023-12-04 11:24:52 INFO     Adding Sequence(ClassLabel) feature to dataset to make it usable with the `TokenClassificationEvaluator` from `evaluation`.\n",
      "Read more: https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "201506a280db49658baa665abc03f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490af76b99aa42e688b4d5d7b0bac152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc25331cbd3b4d468556abfff3c841a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:24:55 INFO     Filtered language by en. \n",
      "DatasetDict({\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 32908\n",
      "    })\n",
      "})\n",
      "2023-12-04 11:24:55 INFO     Keeping these tags only: ['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-DIS', 'I-DIS']. All other tags will be set to '0'\n",
      "2023-12-04 11:24:55 INFO     Making sure all labels have sequential IDs. This can happen if a reduced tagset is chosen\n",
      "2023-12-04 11:24:55 INFO     Swapping these labels: {14: 10, 13: 9}\n",
      "2023-12-04 11:24:55 INFO     Modified label to ID: {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6, 'B-ANIM': 7, 'I-ANIM': 8, 'B-DIS': 9, 'I-DIS': 10}\n",
      "2023-12-04 11:24:55 INFO     Modified ID to label: {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC', 7: 'B-ANIM', 8: 'I-ANIM', 9: 'B-DIS', 10: 'I-DIS'}\n",
      "2023-12-04 11:24:55 INFO     Adding Sequence(ClassLabel) feature to dataset to make it usable with the `TokenClassificationEvaluator` from `evaluation`.\n",
      "Read more: https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes\n"
     ]
    }
   ],
   "source": [
    "# uses the entire MultiNERD tagset\n",
    "A = PrepSystem(labels=TagInfo.full_tagset,\n",
    "                pretrained_model_checkpoint=pretrained_model_checkpoint,\n",
    "                dataset_batch_size=16,\n",
    "                filter_tagset=False,\n",
    "                language=filter_by_lang,\n",
    "                split_filter=\"test\"\n",
    "                )\n",
    "\n",
    "# uses only PER, ORG, LOC, DIS, ANIM\n",
    "B = PrepSystem(labels=TagInfo.main_five, \n",
    "                pretrained_model_checkpoint=pretrained_model_checkpoint,\n",
    "                dataset_batch_size=16,\n",
    "                filter_tagset=True,\n",
    "                language=filter_by_lang,\n",
    "                split_filter=\"test\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the `evaluator`, the dataset features need to contain a `ClassLabel`. These have been added by the `PrepSystem` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-BIO', 'I-BIO', 'B-CEL', 'I-CEL', 'B-DIS', 'I-DIS', 'B-EVE', 'I-EVE', 'B-FOOD', 'I-FOOD', 'B-INST', 'I-INST', 'B-MEDIA', 'I-MEDIA', 'B-MYTH', 'I-MYTH', 'B-PLANT', 'I-PLANT', 'B-TIME', 'I-TIME', 'B-VEHI', 'I-VEHI'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System A has the full tagset \n",
    "A.dataset[\"test\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-DIS', 'I-DIS'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# System B has only five + the '0' tag\n",
    "B.dataset[\"test\"].features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[`evaluate.TokenClassificationEvaluator`](https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes#evaluate.TokenClassificationEvaluator) can compute metrics for this specific task.\n",
    "\n",
    "The metric used here is [seqeval](https://huggingface.co/spaces/evaluate-metric/seqeval) to calculate precision, recall, and f1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is tqdm progress bar enabled? True\n"
     ]
    }
   ],
   "source": [
    "utils.logging.set_verbosity(10)\n",
    "enable_progress_bar()\n",
    "print(\"Is tqdm progress bar enabled?\", is_progress_bar_enabled())\n",
    "\n",
    "task_evaluator = evaluator(\"token-classification\")\n",
    "metric = \"seqeval\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The finetuned models can be loaded from hugginface.\n",
    "\n",
    "It's also possible to load the model if stored locally\n",
    "\n",
    "```python\n",
    "locally_stored_model = TFAutoModelForTokenClassification.from_pretrained(\"./model_dir\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_A = \"i-be-snek/distilbert-base-uncased-finetuned-ner-exp_A\"\n",
    "exp_B = \"i-be-snek/distilbert-base-uncased-finetuned-ner-exp_B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:24:56.074698: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:56.074870: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:56.074944: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:56.126581: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:56.126706: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:56.126781: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-12-04 11:24:56.126842: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 11:24:56.126903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3992 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-12-04 11:24:56.393175: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "All model checkpoint layers were used when initializing TFDistilBertForTokenClassification.\n",
      "\n",
      "All the layers of TFDistilBertForTokenClassification were initialized from the model checkpoint at i-be-snek/distilbert-base-uncased-finetuned-ner-exp_A.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFDistilBertForTokenClassification for predictions without further training.\n",
      "Some layers from the model checkpoint at i-be-snek/distilbert-base-uncased-finetuned-ner-exp_B were not used when initializing TFDistilBertForTokenClassification: ['dropout_19']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFDistilBertForTokenClassification were not initialized from the model checkpoint at i-be-snek/distilbert-base-uncased-finetuned-ner-exp_B and are newly initialized: ['dropout_39']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "finetuned_model_A = TFAutoModelForTokenClassification.from_pretrained(exp_A)\n",
    "finetuned_model_B = TFAutoModelForTokenClassification.from_pretrained(exp_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenizer can also be loaded from hugginface. \n",
    "\n",
    "Alternatively, the tokenizer could be loaded from `PrepSystem`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_A = AutoTokenizer.from_pretrained(\"i-be-snek/distilbert-base-uncased-finetuned-ner-exp_A\")\n",
    "# tokenizer_B = AutoTokenizer.from_pretrained(\"i-be-snek/distilbert-base-uncased-finetuned-ner-exp_B\")\n",
    "\n",
    "# A.load_tokenizer()\n",
    "# tokenizer_A = A.tokenizer\n",
    "B.load_tokenizer()\n",
    "tokenizer_B = B.tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation may take up to 20-30 minutes to evaluate on GPU on the full test set.\n",
    "\n",
    "To evaluate on a small subset of the test data, use `.select`\n",
    "\n",
    "```python\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=my_finetuned_model,\n",
    "    data=my_dataset[\"test\"].select(range(100)),\n",
    "    tokenizer=my_tokenizer,\n",
    "    metric=my_metric,\n",
    "    device=0,\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:25:01 DEBUG    Checking /home/snek/.cache/huggingface/evaluate/downloads/ce3d470a80c053c9717f2e2f5afecd57e33d25206350f19ddc705fff68aabbe8.39fd158e256d7438039bca37be07c68d2db98a59b944148d8fb5bd3d080432bc.py for additional imports.\n",
      "2023-12-04 11:25:01 DEBUG    Created importable dataset file at /home/snek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c/seqeval.py\n",
      "2023-12-04 11:50:00 INFO     Removing /home/snek/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ANIM': {'precision': 0.6672619047619047,\n",
       "  'recall': 0.6988778054862843,\n",
       "  'f1': 0.6827040194884287,\n",
       "  'number': 3208},\n",
       " 'BIO': {'precision': 0.6666666666666666,\n",
       "  'recall': 0.75,\n",
       "  'f1': 0.7058823529411765,\n",
       "  'number': 16},\n",
       " 'CEL': {'precision': 0.5081967213114754,\n",
       "  'recall': 0.7560975609756098,\n",
       "  'f1': 0.6078431372549019,\n",
       "  'number': 82},\n",
       " 'DIS': {'precision': 0.6623235613463626,\n",
       "  'recall': 0.8036890645586298,\n",
       "  'f1': 0.726190476190476,\n",
       "  'number': 1518},\n",
       " 'EVE': {'precision': 0.8962765957446809,\n",
       "  'recall': 0.9573863636363636,\n",
       "  'f1': 0.9258241758241759,\n",
       "  'number': 704},\n",
       " 'FOOD': {'precision': 0.6378091872791519,\n",
       "  'recall': 0.6378091872791519,\n",
       "  'f1': 0.6378091872791519,\n",
       "  'number': 1132},\n",
       " 'INST': {'precision': 0.6428571428571429,\n",
       "  'recall': 0.75,\n",
       "  'f1': 0.6923076923076924,\n",
       "  'number': 24},\n",
       " 'LOC': {'precision': 0.9641371276418705,\n",
       "  'recall': 0.9636560212907518,\n",
       "  'f1': 0.9638965144330754,\n",
       "  'number': 24048},\n",
       " 'MEDIA': {'precision': 0.9319148936170213,\n",
       "  'recall': 0.9563318777292577,\n",
       "  'f1': 0.9439655172413792,\n",
       "  'number': 916},\n",
       " 'MYTH': {'precision': 0.6388888888888888,\n",
       "  'recall': 0.71875,\n",
       "  'f1': 0.676470588235294,\n",
       "  'number': 64},\n",
       " 'ORG': {'precision': 0.9411764705882353,\n",
       "  'recall': 0.962224236929586,\n",
       "  'f1': 0.9515839808726839,\n",
       "  'number': 6618},\n",
       " 'PER': {'precision': 0.9903299203640501,\n",
       "  'recall': 0.992022792022792,\n",
       "  'f1': 0.991175633361799,\n",
       "  'number': 10530},\n",
       " 'PLANT': {'precision': 0.5580431177446102,\n",
       "  'recall': 0.7527964205816555,\n",
       "  'f1': 0.6409523809523809,\n",
       "  'number': 1788},\n",
       " 'TIME': {'precision': 0.756578947368421,\n",
       "  'recall': 0.7958477508650519,\n",
       "  'f1': 0.7757166947723441,\n",
       "  'number': 578},\n",
       " 'VEHI': {'precision': 0.7352941176470589,\n",
       "  'recall': 0.78125,\n",
       "  'f1': 0.7575757575757576,\n",
       "  'number': 64},\n",
       " 'overall_precision': 0.9053582270795385,\n",
       " 'overall_recall': 0.9303178007408852,\n",
       " 'overall_f1': 0.9176683270188665,\n",
       " 'overall_accuracy': 0.9863554498955407,\n",
       " 'total_time_in_seconds': 1489.770161871,\n",
       " 'samples_per_second': 22.08931340031062,\n",
       " 'latency_in_seconds': 0.04527075975054698}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_A = task_evaluator.compute(\n",
    "    model_or_pipeline=finetuned_model_A,\n",
    "    data=A.dataset[\"test\"],\n",
    "    tokenizer=tokenizer_A,\n",
    "    metric=metric,\n",
    "    device=0,\n",
    ")\n",
    "results_A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 11:50:07 DEBUG    Checking /home/snek/.cache/huggingface/evaluate/downloads/ce3d470a80c053c9717f2e2f5afecd57e33d25206350f19ddc705fff68aabbe8.39fd158e256d7438039bca37be07c68d2db98a59b944148d8fb5bd3d080432bc.py for additional imports.\n",
      "2023-12-04 11:50:07 DEBUG    Created importable dataset file at /home/snek/.cache/huggingface/modules/evaluate_modules/metrics/evaluate-metric--seqeval/541ae017dc683f85116597d48f621abc7b21b88dc42ec937c71af5415f0af63c/seqeval.py\n",
      "2023-12-04 12:14:48 INFO     Removing /home/snek/.cache/huggingface/metrics/seqeval/default/default_experiment-1-0.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ANIM': {'precision': 0.6746031746031746,\n",
       "  'recall': 0.7948877805486284,\n",
       "  'f1': 0.7298225529479108,\n",
       "  'number': 3208},\n",
       " 'DIS': {'precision': 0.695303550973654,\n",
       "  'recall': 0.7997364953886693,\n",
       "  'f1': 0.7438725490196079,\n",
       "  'number': 1518},\n",
       " 'LOC': {'precision': 0.9666694372870086,\n",
       "  'recall': 0.9672322022621423,\n",
       "  'f1': 0.96695073789233,\n",
       "  'number': 24048},\n",
       " 'ORG': {'precision': 0.9547123623011016,\n",
       "  'recall': 0.942883046237534,\n",
       "  'f1': 0.9487608332066291,\n",
       "  'number': 6618},\n",
       " 'PER': {'precision': 0.9890483383685801,\n",
       "  'recall': 0.9948717948717949,\n",
       "  'f1': 0.9919515197424487,\n",
       "  'number': 10530},\n",
       " 'overall_precision': 0.9362959157462112,\n",
       " 'overall_recall': 0.9524846478811898,\n",
       " 'overall_f1': 0.9443209050281742,\n",
       " 'overall_accuracy': 0.9913435631438657,\n",
       " 'total_time_in_seconds': 1472.2920382579998,\n",
       " 'samples_per_second': 22.351543813913707,\n",
       " 'latency_in_seconds': 0.044739638940622335}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_B = task_evaluator.compute(\n",
    "    model_or_pipeline=finetuned_model_B,\n",
    "    data=B.dataset[\"test\"],\n",
    "    tokenizer=tokenizer_B,\n",
    "    metric=metric,\n",
    "    device=0,\n",
    ")\n",
    "results_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment A evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ANIM        BIO        CEL          DIS         EVE  \\\n",
      "precision     0.667262   0.666667   0.508197     0.662324    0.896277   \n",
      "recall        0.698878   0.750000   0.756098     0.803689    0.957386   \n",
      "f1            0.682704   0.705882   0.607843     0.726190    0.925824   \n",
      "number     3208.000000  16.000000  82.000000  1518.000000  704.000000   \n",
      "\n",
      "                  FOOD       INST           LOC       MEDIA       MYTH  \\\n",
      "precision     0.637809   0.642857      0.964137    0.931915   0.638889   \n",
      "recall        0.637809   0.750000      0.963656    0.956332   0.718750   \n",
      "f1            0.637809   0.692308      0.963897    0.943966   0.676471   \n",
      "number     1132.000000  24.000000  24048.000000  916.000000  64.000000   \n",
      "\n",
      "                   ORG           PER        PLANT        TIME       VEHI  \n",
      "precision     0.941176      0.990330     0.558043    0.756579   0.735294  \n",
      "recall        0.962224      0.992023     0.752796    0.795848   0.781250  \n",
      "f1            0.951584      0.991176     0.640952    0.775717   0.757576  \n",
      "number     6618.000000  10530.000000  1788.000000  578.000000  64.000000  \n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(results_A).iloc[:, :15])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metric     value\n",
      "0  precision  0.905358\n",
      "1     recall  0.930318\n",
      "2         f1  0.917668\n",
      "3   accuracy  0.986355\n"
     ]
    }
   ],
   "source": [
    "results_A_overall = {key.split(\"_\")[1]: value for key, value in results_A.items() if key.startswith(\"overall_\")}\n",
    "\n",
    "\n",
    "print(pd.DataFrame(list(results_A_overall.items()), columns=[\"metric\", \"value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment B evaluation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  ANIM          DIS           LOC          ORG           PER\n",
      "precision     0.674603     0.695304      0.966669     0.954712      0.989048\n",
      "recall        0.794888     0.799736      0.967232     0.942883      0.994872\n",
      "f1            0.729823     0.743873      0.966951     0.948761      0.991952\n",
      "number     3208.000000  1518.000000  24048.000000  6618.000000  10530.000000\n"
     ]
    }
   ],
   "source": [
    "print(pd.DataFrame(results_B).iloc[:, :5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      metric     value\n",
      "0  precision  0.905358\n",
      "1     recall  0.930318\n",
      "2         f1  0.917668\n",
      "3   accuracy  0.986355\n"
     ]
    }
   ],
   "source": [
    "results_B_overall = {key.split(\"_\")[1]: value for key, value in results_B.items() if key.startswith(\"overall_\")}\n",
    "print(pd.DataFrame(list(results_A_overall.items()), columns=[\"metric\", \"value\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results can be pushed to the huggingface hub using the `evaluate` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537eb02a39a14df6a3f604a8696a36a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.96k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2baac8343ba4c26a5cf6a7f8e827ce8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.03k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25fd229accb4ab6bd73f667ab732b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/8.10k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in results_A_overall.items():\n",
    "    push_to_hub(model_id=exp_A,\n",
    "                task_type=\"token-classification\",\n",
    "                dataset_type=\"Babelscape/multinerd\",\n",
    "                dataset_name=\"Babelscape/multinerd\",\n",
    "                metric_type=metric,\n",
    "                metric_name=k,\n",
    "                metric_value=float(v),\n",
    "                dataset_split=\"test\",\n",
    "                task_name=\"ner\",\n",
    "                overwrite=True\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f57a5559a24263befa5b16c2b8568f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.30k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44dedfbe5d549ffa04746af0dd96953",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16e1450b8d5433594ee4d28e4fae3d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dee62831e724e5b884c6f9eb305375a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/4.69k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for k, v in results_B_overall.items():\n",
    "    push_to_hub(model_id=exp_B,\n",
    "                task_type=\"token-classification\",\n",
    "                dataset_type=\"Babelscape/multinerd\",\n",
    "                dataset_name=\"Babelscape/multinerd with only 5 tags\",\n",
    "                metric_type=metric,\n",
    "                metric_name=k,\n",
    "                metric_value=float(v),\n",
    "                dataset_split=\"test\",\n",
    "                task_name=\"ner\",\n",
    "                overwrite=True\n",
    "                )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
