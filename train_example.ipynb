{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:07:47.083390: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 19:07:47.111482: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 19:07:47.111509: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 19:07:47.111536: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 19:07:47.116488: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from src.preprocess import PrepSystem\n",
    "from src.train import train\n",
    "from transformers import AdamWeightDecay\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_labels_in_config(id2label: dict[int, str], labels_to_swap: dict[int, int]):\n",
    "        to_swap = list(labels_to_swap.keys())\n",
    "        id2label = dict(sorted(id2label.items()))\n",
    "        new_id2label = {}\n",
    "        \n",
    "        new_index = 0\n",
    "        #for i in id2label.values():\n",
    "        #        new_id2label[new_index] = i\n",
    "        #        new_index += 1\n",
    "\n",
    "\n",
    "        #for _id, _label in id2label.items():\n",
    "        #    if _id in to_swap:\n",
    "        #        new_id2label[labels_to_swap[_id]] = _label\n",
    "        #    else:\n",
    "        #        new_id2label[_id] = _label\n",
    "        # for k, v in labels_to_swap.items():\n",
    "        #     id2label[v] = id2label[k]\n",
    "# \n",
    "        # for i in list(labels_to_swap.keys()):\n",
    "        #     id2label.pop(i)\n",
    "# \n",
    "        id2label = dict(sorted(new_id2label.items()))\n",
    "        label2id = {v: k for k, v in id2label.items()}\n",
    "        return label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def swap_labels_in_config(label2id: dict[int, str], labels_to_swap: dict[int, int]):\n",
    "\n",
    "    label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "    for _label, _id in label2id.items():\n",
    "        print(_label, _id)\n",
    "        label2id[_label] = labels_to_swap[_id]\n",
    "        \n",
    "    id2label = {v: k for k, v in label2id.items()}\n",
    "\n",
    "    return label2id, id2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = {\n",
    "        \"O\": 0,\n",
    "        \"B-PER\": 1,\n",
    "        \"I-PER\": 2,\n",
    "        # \"B-ORG\": 3,\n",
    "        # \"I-ORG\": 4,\n",
    "        \"B-LOC\": 5,\n",
    "        \"I-LOC\": 6,\n",
    "        #\"B-ANIM\": 7,\n",
    "        #\"I-ANIM\": 8,\n",
    "        \"B-DIS\": 13,\n",
    "        \"I-DIS\": 14,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'O',\n",
       " 1: 'B-PER',\n",
       " 2: 'I-PER',\n",
       " 5: 'B-LOC',\n",
       " 6: 'I-LOC',\n",
       " 13: 'B-DIS',\n",
       " 14: 'I-DIS'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label2id = {v: k for k, v in tagset.items()}\n",
    "label2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/snek/rise-assignment-ner-finetune/train_example.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m swap_labels_in_config(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     label2id, {\u001b[39m5\u001b[39;49m: \u001b[39m3\u001b[39;49m, \u001b[39m6\u001b[39;49m: \u001b[39m4\u001b[39;49m, \u001b[39m7\u001b[39;49m: \u001b[39m5\u001b[39;49m, \u001b[39m8\u001b[39;49m: \u001b[39m6\u001b[39;49m, \u001b[39m13\u001b[39;49m: \u001b[39m7\u001b[39;49m, \u001b[39m14\u001b[39;49m: \u001b[39m8\u001b[39;49m}\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m )\n",
      "\u001b[1;32m/home/snek/rise-assignment-ner-finetune/train_example.ipynb Cell 6\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m _label, _id \u001b[39min\u001b[39;00m label2id\u001b[39m.\u001b[39mitems():\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mprint\u001b[39m(_label, _id)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     label2id[_label] \u001b[39m=\u001b[39m labels_to_swap[_id]\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m id2label \u001b[39m=\u001b[39m {v: k \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m label2id\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W3sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mreturn\u001b[39;00m label2id, id2label\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "swap_labels_in_config(\n",
    "    label2id, {5: 3, 6: 4, 7: 5, 8: 6, 13: 7, 14: 8}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:07:48 INFO     [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2023-12-04 19:07:48.133603: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 19:07:48.137890: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 19:07:48.138033: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from src.train import check_gpus\n",
    "check_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "345dbac495ca4d5d8bc20c6b0f1299cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AdamWeightDecay' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/snek/rise-assignment-ner-finetune/train_example.ipynb Cell 7\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pretrained_model_checkpoint \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdistilbert-base-uncased\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W6sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m learning_rate \u001b[39m=\u001b[39m \u001b[39m2e-5\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W6sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m optimizer \u001b[39m=\u001b[39m AdamWeightDecay(learning_rate\u001b[39m=\u001b[39mlearning_rate, weight_decay_rate\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W6sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m filter_tagset \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W6sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m# any limited tagset works\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W6sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m# for example, here we remove \"ORG\" from the tagset for experiment B\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AdamWeightDecay' is not defined"
     ]
    }
   ],
   "source": [
    "pretrained_model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "learning_rate = 2e-5\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=0.0)\n",
    "\n",
    "filter_tagset = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# any limited tagset works\n",
    "# for example, here we remove \"ORG\" from the tagset for experiment B\n",
    "tagset = {\n",
    "        \"O\": 0,\n",
    "        \"B-PER\": 1,\n",
    "        \"I-PER\": 2,\n",
    "        # \"B-ORG\": 3,\n",
    "        # \"I-ORG\": 4,\n",
    "        \"B-LOC\": 5,\n",
    "        \"I-LOC\": 6,\n",
    "        \"B-ANIM\": 7,\n",
    "        \"I-ANIM\": 8,\n",
    "        \"B-DIS\": 13,\n",
    "        \"I-DIS\": 14,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883d98ea5de94f519ee30d9d74c8e5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be3868c7c794bef9f161be8b13b3e7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb3c853f17d4e0c9c6c80e1330b1dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:07:59 INFO     Filtered language by en. \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 262560\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 32820\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 32908\n",
      "    })\n",
      "})\n",
      "2023-12-04 19:07:59 INFO     Keeping these tags only: ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-DIS', 'I-DIS']. All other tags will be set to '0'\n",
      "2023-12-04 19:07:59 INFO     Making sure all labels have sequential IDs. This can happen if a reduced tagset is chosen\n",
      "2023-12-04 19:07:59 INFO     Swapping these labels: {14: 8, 13: 7, 8: 6, 7: 5, 6: 4, 5: 3}\n",
      "2023-12-04 19:07:59 INFO     Modified label to ID: {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-DIS': 3, 'I-DIS': 4}\n",
      "2023-12-04 19:07:59 INFO     Modified ID to label: {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-DIS', 4: 'I-DIS'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ddf8e3204f4f9a8603ab8cffffb1ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/262560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e284a209bde43a8831da40b7e601811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/32820 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "084e818d22834910a59bc36cbac6038f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=4):   0%|          | 0/32908 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 19:08:03 INFO     Adding Sequence(ClassLabel) feature to dataset to make it usable with the `TokenClassificationEvaluator` from `evaluation`.\n",
      "Read more: https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f3a429d41145fab657abc8754892a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/262560 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "Class label 8 greater than configured num_classes 5",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3452\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3451\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 3452\u001b[0m         writer\u001b[39m.\u001b[39;49mwrite(example)\n\u001b[1;32m   3453\u001b[0m num_examples_progress_update \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_writer.py:491\u001b[0m, in \u001b[0;36mArrowWriter.write\u001b[0;34m(self, example, key, writer_batch_size)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhkey_record \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 491\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_examples_on_file()\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_writer.py:449\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m         batch_examples[col] \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m             row[\u001b[39m0\u001b[39m][col]\u001b[39m.\u001b[39mto_pylist()[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(row[\u001b[39m0\u001b[39m][col], (pa\u001b[39m.\u001b[39mArray, pa\u001b[39m.\u001b[39mChunkedArray)) \u001b[39melse\u001b[39;00m row[\u001b[39m0\u001b[39m][col]\n\u001b[1;32m    447\u001b[0m             \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples\n\u001b[1;32m    448\u001b[0m         ]\n\u001b[0;32m--> 449\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_batch(batch_examples\u001b[39m=\u001b[39;49mbatch_examples)\n\u001b[1;32m    450\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_writer.py:550\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(col_values, (pa\u001b[39m.\u001b[39mArray, pa\u001b[39m.\u001b[39mChunkedArray)):\n\u001b[0;32m--> 550\u001b[0m     array \u001b[39m=\u001b[39m cast_array_to_feature(col_values, col_type) \u001b[39mif\u001b[39;00m col_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m col_values\n\u001b[1;32m    551\u001b[0m     arrays\u001b[39m.\u001b[39mappend(array)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:1836\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1836\u001b[0m     \u001b[39mreturn\u001b[39;00m func(array, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:2099\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_number_to_str)\u001b[0m\n\u001b[1;32m   2098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2099\u001b[0m     casted_values \u001b[39m=\u001b[39m _c(array\u001b[39m.\u001b[39;49mvalues, feature\u001b[39m.\u001b[39;49mfeature)\n\u001b[1;32m   2100\u001b[0m     \u001b[39mif\u001b[39;00m casted_values\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m array\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtype:\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:1836\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1836\u001b[0m     \u001b[39mreturn\u001b[39;00m func(array, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:2066\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_number_to_str)\u001b[0m\n\u001b[1;32m   2065\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(feature, \u001b[39m\"\u001b[39m\u001b[39mcast_storage\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 2066\u001b[0m     \u001b[39mreturn\u001b[39;00m feature\u001b[39m.\u001b[39;49mcast_storage(array)\n\u001b[1;32m   2068\u001b[0m \u001b[39melif\u001b[39;00m pa\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mis_struct(array\u001b[39m.\u001b[39mtype):\n\u001b[1;32m   2069\u001b[0m     \u001b[39m# feature must be a dict or Sequence(subfeatures_dict)\u001b[39;00m\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/features/features.py:1113\u001b[0m, in \u001b[0;36mClassLabel.cast_storage\u001b[0;34m(self, storage)\u001b[0m\n\u001b[1;32m   1112\u001b[0m     \u001b[39mif\u001b[39;00m min_max[\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m min_max[\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes:\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1114\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mClass label \u001b[39m\u001b[39m{\u001b[39;00mmin_max[\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m greater than configured num_classes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m         )\n\u001b[1;32m   1116\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(storage, pa\u001b[39m.\u001b[39mStringArray):\n",
      "\u001b[0;31mValueError\u001b[0m: Class label 8 greater than configured num_classes 5",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/snek/rise-assignment-ner-finetune/train_example.ipynb Cell 5\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m system \u001b[39m=\u001b[39m PrepSystem(\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m         labels\u001b[39m=\u001b[39;49mtagset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m         pretrained_model_checkpoint\u001b[39m=\u001b[39;49mpretrained_model_checkpoint,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         dataset_batch_size\u001b[39m=\u001b[39;49m\u001b[39m16\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         filter_tagset\u001b[39m=\u001b[39;49mfilter_tagset,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         language\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39men\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         split_filter\u001b[39m=\u001b[39;49m\u001b[39mNone\u001b[39;49;00m,  \u001b[39m# None to load the entire dataset\u001b[39;49;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/snek/rise-assignment-ner-finetune/train_example.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     )\n",
      "File \u001b[0;32m<string>:10\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, labels, pretrained_model_checkpoint, dataset_batch_size, filter_tagset, language, huggingface_dataset_name, split_filter)\u001b[0m\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/src/preprocess.py:126\u001b[0m, in \u001b[0;36mPrepSystem.__post_init__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[ds]\u001b[39m.\u001b[39mfeatures\u001b[39m.\u001b[39mcopy()\n\u001b[1;32m    125\u001b[0m features[\u001b[39m\"\u001b[39m\u001b[39mner_tags\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m Sequence(feature\u001b[39m=\u001b[39mClassLabel(names\u001b[39m=\u001b[39mclass_labels))\n\u001b[0;32m--> 126\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[ds] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[ds]\u001b[39m.\u001b[39;49mmap(features\u001b[39m=\u001b[39;49mfeatures)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:591\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    590\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    592\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    593\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    594\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:556\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    549\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    550\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    551\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    552\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    553\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    554\u001b[0m }\n\u001b[1;32m    555\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 556\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    557\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    558\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3089\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   3082\u001b[0m \u001b[39mif\u001b[39;00m transformed_dataset \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3083\u001b[0m     \u001b[39mwith\u001b[39;00m logging\u001b[39m.\u001b[39mtqdm(\n\u001b[1;32m   3084\u001b[0m         disable\u001b[39m=\u001b[39m\u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled(),\n\u001b[1;32m   3085\u001b[0m         unit\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m examples\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3086\u001b[0m         total\u001b[39m=\u001b[39mpbar_total,\n\u001b[1;32m   3087\u001b[0m         desc\u001b[39m=\u001b[39mdesc \u001b[39mor\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mMap\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   3088\u001b[0m     ) \u001b[39mas\u001b[39;00m pbar:\n\u001b[0;32m-> 3089\u001b[0m         \u001b[39mfor\u001b[39;00m rank, done, content \u001b[39min\u001b[39;00m Dataset\u001b[39m.\u001b[39m_map_single(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdataset_kwargs):\n\u001b[1;32m   3090\u001b[0m             \u001b[39mif\u001b[39;00m done:\n\u001b[1;32m   3091\u001b[0m                 shards_done \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_dataset.py:3497\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(shard, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset)\u001b[0m\n\u001b[1;32m   3495\u001b[0m \u001b[39mif\u001b[39;00m update_data:\n\u001b[1;32m   3496\u001b[0m     \u001b[39mif\u001b[39;00m writer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 3497\u001b[0m         writer\u001b[39m.\u001b[39;49mfinalize()\n\u001b[1;32m   3498\u001b[0m     \u001b[39mif\u001b[39;00m tmp_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   3499\u001b[0m         tmp_file\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_writer.py:587\u001b[0m, in \u001b[0;36mArrowWriter.finalize\u001b[0;34m(self, close_stream)\u001b[0m\n\u001b[1;32m    585\u001b[0m     \u001b[39m# Re-intializing to empty list for next batch\u001b[39;00m\n\u001b[1;32m    586\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhkey_record \u001b[39m=\u001b[39m []\n\u001b[0;32m--> 587\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_examples_on_file()\n\u001b[1;32m    588\u001b[0m \u001b[39m# If schema is known, infer features even if no examples were written\u001b[39;00m\n\u001b[1;32m    589\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpa_writer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mschema:\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_writer.py:449\u001b[0m, in \u001b[0;36mArrowWriter.write_examples_on_file\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    445\u001b[0m         batch_examples[col] \u001b[39m=\u001b[39m [\n\u001b[1;32m    446\u001b[0m             row[\u001b[39m0\u001b[39m][col]\u001b[39m.\u001b[39mto_pylist()[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(row[\u001b[39m0\u001b[39m][col], (pa\u001b[39m.\u001b[39mArray, pa\u001b[39m.\u001b[39mChunkedArray)) \u001b[39melse\u001b[39;00m row[\u001b[39m0\u001b[39m][col]\n\u001b[1;32m    447\u001b[0m             \u001b[39mfor\u001b[39;00m row \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples\n\u001b[1;32m    448\u001b[0m         ]\n\u001b[0;32m--> 449\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwrite_batch(batch_examples\u001b[39m=\u001b[39;49mbatch_examples)\n\u001b[1;32m    450\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcurrent_examples \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/arrow_writer.py:550\u001b[0m, in \u001b[0;36mArrowWriter.write_batch\u001b[0;34m(self, batch_examples, writer_batch_size)\u001b[0m\n\u001b[1;32m    548\u001b[0m col_type \u001b[39m=\u001b[39m features[col] \u001b[39mif\u001b[39;00m features \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(col_values, (pa\u001b[39m.\u001b[39mArray, pa\u001b[39m.\u001b[39mChunkedArray)):\n\u001b[0;32m--> 550\u001b[0m     array \u001b[39m=\u001b[39m cast_array_to_feature(col_values, col_type) \u001b[39mif\u001b[39;00m col_type \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m col_values\n\u001b[1;32m    551\u001b[0m     arrays\u001b[39m.\u001b[39mappend(array)\n\u001b[1;32m    552\u001b[0m     inferred_features[col] \u001b[39m=\u001b[39m generate_from_arrow_type(col_values\u001b[39m.\u001b[39mtype)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:1836\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mchunked_array([func(chunk, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m array\u001b[39m.\u001b[39mchunks])\n\u001b[1;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1836\u001b[0m     \u001b[39mreturn\u001b[39;00m func(array, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:2099\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_number_to_str)\u001b[0m\n\u001b[1;32m   2097\u001b[0m         \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mFixedSizeListArray\u001b[39m.\u001b[39mfrom_arrays(_c(array\u001b[39m.\u001b[39mvalues, feature\u001b[39m.\u001b[39mfeature), feature\u001b[39m.\u001b[39mlength)\n\u001b[1;32m   2098\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2099\u001b[0m     casted_values \u001b[39m=\u001b[39m _c(array\u001b[39m.\u001b[39;49mvalues, feature\u001b[39m.\u001b[39;49mfeature)\n\u001b[1;32m   2100\u001b[0m     \u001b[39mif\u001b[39;00m casted_values\u001b[39m.\u001b[39mtype \u001b[39m==\u001b[39m array\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mtype:\n\u001b[1;32m   2101\u001b[0m         \u001b[39mreturn\u001b[39;00m array\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:1836\u001b[0m, in \u001b[0;36m_wrap_for_chunked_arrays.<locals>.wrapper\u001b[0;34m(array, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mchunked_array([func(chunk, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs) \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m array\u001b[39m.\u001b[39mchunks])\n\u001b[1;32m   1835\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1836\u001b[0m     \u001b[39mreturn\u001b[39;00m func(array, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/table.py:2066\u001b[0m, in \u001b[0;36mcast_array_to_feature\u001b[0;34m(array, feature, allow_number_to_str)\u001b[0m\n\u001b[1;32m   2064\u001b[0m     array \u001b[39m=\u001b[39m array\u001b[39m.\u001b[39mstorage\n\u001b[1;32m   2065\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(feature, \u001b[39m\"\u001b[39m\u001b[39mcast_storage\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 2066\u001b[0m     \u001b[39mreturn\u001b[39;00m feature\u001b[39m.\u001b[39;49mcast_storage(array)\n\u001b[1;32m   2068\u001b[0m \u001b[39melif\u001b[39;00m pa\u001b[39m.\u001b[39mtypes\u001b[39m.\u001b[39mis_struct(array\u001b[39m.\u001b[39mtype):\n\u001b[1;32m   2069\u001b[0m     \u001b[39m# feature must be a dict or Sequence(subfeatures_dict)\u001b[39;00m\n\u001b[1;32m   2070\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(feature, Sequence) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(feature\u001b[39m.\u001b[39mfeature, \u001b[39mdict\u001b[39m):\n",
      "File \u001b[0;32m~/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/datasets/features/features.py:1113\u001b[0m, in \u001b[0;36mClassLabel.cast_storage\u001b[0;34m(self, storage)\u001b[0m\n\u001b[1;32m   1111\u001b[0m     min_max \u001b[39m=\u001b[39m pc\u001b[39m.\u001b[39mmin_max(storage)\u001b[39m.\u001b[39mas_py()\n\u001b[1;32m   1112\u001b[0m     \u001b[39mif\u001b[39;00m min_max[\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m min_max[\u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes:\n\u001b[0;32m-> 1113\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1114\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mClass label \u001b[39m\u001b[39m{\u001b[39;00mmin_max[\u001b[39m'\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m greater than configured num_classes \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_classes\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1115\u001b[0m         )\n\u001b[1;32m   1116\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(storage, pa\u001b[39m.\u001b[39mStringArray):\n\u001b[1;32m   1117\u001b[0m     storage \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39marray(\n\u001b[1;32m   1118\u001b[0m         [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_strval2int(label) \u001b[39mif\u001b[39;00m label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mfor\u001b[39;00m label \u001b[39min\u001b[39;00m storage\u001b[39m.\u001b[39mto_pylist()]\n\u001b[1;32m   1119\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Class label 8 greater than configured num_classes 5"
     ]
    }
   ],
   "source": [
    "system = PrepSystem(\n",
    "        labels=tagset,\n",
    "        pretrained_model_checkpoint=pretrained_model_checkpoint,\n",
    "        dataset_batch_size=16,\n",
    "        filter_tagset=filter_tagset,\n",
    "        language=\"en\",\n",
    "        # set split_filter to None to load the entire dataset\n",
    "        split_filter=None,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 262560\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 32820\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 32908\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_token_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  8459      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66371339 (253.19 MB)\n",
      "Trainable params: 66371339 (253.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "system.get_model()\n",
    "system.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2023, 2003, 2005, 2043, 2017, 2131, 3236, 1999, 1037, 3637, 1011, 11421, 1998, 1996, 3712, 2003, 2041, 1997, 2344, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'for',\n",
       " 'when',\n",
       " 'you',\n",
       " 'get',\n",
       " 'caught',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sleep',\n",
       " '-',\n",
       " 'riot',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'is',\n",
       " 'out',\n",
       " 'of',\n",
       " 'order',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.load_tokenizer()\n",
    "sentence = \"This is for when you get caught in a sleep-riot and the sky is out of order\"\n",
    "tokenized = system.tokenizer(sentence.split(\" \"), truncation=True,\n",
    "            is_split_into_words=True)\n",
    "print(tokenized[\"input_ids\"])\n",
    "system.tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a smaller subset of the dataset \n",
    "num_examples = 1000\n",
    "for ds in system.data_split:\n",
    "    system.dataset[ds] = system.dataset[ds].select(range(num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.tokenize_dataset()\n",
    "system.tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and tokenized.\n",
      "Sample: {'tokens': ['The', 'film', 'stars', 'Natalie', 'Portman', ',', 'Vincent', 'Cassel', ',', 'Mila', 'Kunis', ',', 'Barbara', 'Hershey', ',', 'and', 'Winona', 'Ryder', '.'], 'ner_tags': [0, 0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 0, 1, 2, 0], 'input_ids': [101, 1996, 2143, 3340, 10829, 3417, 2386, 1010, 6320, 16220, 2884, 1010, 23689, 2050, 28919, 2483, 1010, 6437, 5106, 14844, 1010, 1998, 2663, 7856, 11731, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 0, 0, 0, 1, 2, 2, 0, 1, 2, 2, 0, 1, 1, 2, 2, 0, 1, 2, 2, 0, 0, 1, 1, 2, 0, -100]}\n",
      "Decoded: ['[CLS]', 'the', 'film', 'stars', 'natalie', 'port', '##man', ',', 'vincent', 'cass', '##el', ',', 'mil', '##a', 'kun', '##is', ',', 'barbara', 'hers', '##hey', ',', 'and', 'win', '##ona', 'ryder', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sample = system.tokenized_dataset[\"train\"][randint(0, 200)]\n",
    "print(f\"Dataset loaded and tokenized.\\nSample: {sample}\")\n",
    "print(f\"Decoded: {system.tokenizer.convert_ids_to_tokens(sample['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_token_classification_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " dropout_39 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  8459      \n",
      "                                                                 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================================\n",
      "Total params: 66371339 (253.19 MB)\n",
      "Trainable params: 66371339 (253.19 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:29:55 INFO     None\n",
      "2023-12-04 18:29:55 INFO     Early stopping with patience of 2\n",
      "2023-12-04 18:29:55 INFO     Storing model checkpoint at each epoch\n",
      "2023-12-04 18:29:55 INFO     Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/62 [=>............................] - ETA: 7s - loss: 0.9744WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0566s vs `on_train_batch_end` time: 0.0775s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 18:29:59 WARNING  Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0566s vs `on_train_batch_end` time: 0.0775s). Check your callbacks.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - ETA: 0s - loss: 0.5896"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snek/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2023-12-04 18:30:16 INFO     \n",
      "2023-12-04 18:30:16 INFO     Entity: ANIM\n",
      "2023-12-04 18:30:16 INFO     precision \t 0.0\n",
      "2023-12-04 18:30:16 INFO     recall \t 0.0\n",
      "2023-12-04 18:30:16 INFO     f1 \t 0.0\n",
      "2023-12-04 18:30:16 INFO     \n",
      "2023-12-04 18:30:16 INFO     Entity: DIS\n",
      "2023-12-04 18:30:16 INFO     precision \t 0.0\n",
      "2023-12-04 18:30:16 INFO     recall \t 0.0\n",
      "2023-12-04 18:30:16 INFO     f1 \t 0.0\n",
      "2023-12-04 18:30:16 INFO     \n",
      "2023-12-04 18:30:16 INFO     Entity: LOC\n",
      "2023-12-04 18:30:16 INFO     precision \t 0.48\n",
      "2023-12-04 18:30:16 INFO     recall \t 0.03418803418803419\n",
      "2023-12-04 18:30:16 INFO     f1 \t 0.06382978723404256\n",
      "2023-12-04 18:30:16 INFO     \n",
      "2023-12-04 18:30:16 INFO     Entity: ORG\n",
      "2023-12-04 18:30:16 INFO     precision \t 0.0\n",
      "2023-12-04 18:30:16 INFO     recall \t 0.0\n",
      "2023-12-04 18:30:16 INFO     f1 \t 0.0\n",
      "2023-12-04 18:30:16 INFO     \n",
      "2023-12-04 18:30:16 INFO     Entity: PER\n",
      "2023-12-04 18:30:16 INFO     precision \t 0.5740740740740741\n",
      "2023-12-04 18:30:16 INFO     recall \t 0.5081967213114754\n",
      "2023-12-04 18:30:16 INFO     f1 \t 0.5391304347826087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./distilbert-base-uncased-finetuned-ner-my_experiment/checkpoint_01.model.h5\n",
      "62/62 [==============================] - 21s 311ms/step - loss: 0.5896 - val_loss: 0.3512 - precision: 0.5653 - recall: 0.1653 - f1: 0.2558 - accuracy: 0.9128\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"my_experiment\"\n",
    "train(\n",
    "        optimizer=optimizer,\n",
    "        system=system,\n",
    "        verbose=1,\n",
    "        epochs=1,\n",
    "        \n",
    "        # True to generate tensorboard logs\n",
    "        tensorboard_callback=False,\n",
    "\n",
    "        # True to push to hub (make sure you are logged in)\n",
    "        # False to store results locally\n",
    "        push_to_hub_callback=False,\n",
    "\n",
    "        # False to disable\n",
    "        early_stopping=True, \n",
    "        early_stopping_patience=2,\n",
    "        experiment_name=experiment_name,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
