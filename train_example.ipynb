{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:41:21.106863: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-12-04 20:41:21.133485: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-04 20:41:21.133510: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-04 20:41:21.133527: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-04 20:41:21.138482: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import sys\n",
    "\n",
    "parent_dir = os.path.abspath('..')\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "from src.preprocess import PrepSystem\n",
    "from src.train import train\n",
    "from transformers import AdamWeightDecay\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagset = {\n",
    "        \"O\": 0,\n",
    "        \"B-PER\": 1,\n",
    "        \"I-PER\": 2,\n",
    "        # \"B-ORG\": 3,\n",
    "        # \"I-ORG\": 4,\n",
    "        \"B-LOC\": 5,\n",
    "        \"I-LOC\": 6,\n",
    "        #\"B-ANIM\": 7,\n",
    "        #\"I-ANIM\": 8,\n",
    "        \"B-DIS\": 13,\n",
    "        \"I-DIS\": 14,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:41:56.881555: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:41:56 INFO     [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "2023-12-04 20:41:56.885339: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:41:56.885501: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "from src.train import check_gpus\n",
    "check_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38633aaa15d24650920891511226922f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model_checkpoint = \"distilbert-base-uncased\"\n",
    "\n",
    "learning_rate = 2e-5\n",
    "optimizer = AdamWeightDecay(learning_rate=learning_rate, weight_decay_rate=0.0)\n",
    "\n",
    "filter_tagset = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# any limited tagset works\n",
    "# for example, here we remove \"ORG\" from the tagset for experiment B\n",
    "tagset = {\n",
    "        \"O\": 0,\n",
    "        \"B-PER\": 1,\n",
    "        \"I-PER\": 2,\n",
    "        # \"B-ORG\": 3,\n",
    "        # \"I-ORG\": 4,\n",
    "        \"B-LOC\": 5,\n",
    "        \"I-LOC\": 6,\n",
    "        \"B-ANIM\": 7,\n",
    "        \"I-ANIM\": 8,\n",
    "        \"B-DIS\": 13,\n",
    "        \"I-DIS\": 14,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8531a4bb23384647be53551b817a423d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c870c8d41e224a3da11d383e224542ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957dc16aecd544138acb99a1a0e3e2f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:42:11 INFO     Filtered language by en. \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 262560\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 32820\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['tokens', 'ner_tags'],\n",
      "        num_rows: 32908\n",
      "    })\n",
      "})\n",
      "2023-12-04 20:42:11 INFO     Keeping these tags only: ['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-DIS', 'I-DIS']. All other tags will be set to '0'\n",
      "2023-12-04 20:42:11 INFO     Making sure all labels have sequential IDs. This can happen if a reduced tagset is chosen\n",
      "2023-12-04 20:42:11 INFO     Swapping these labels: {14: 8, 13: 7, 8: 6, 7: 5, 6: 4, 5: 3}\n",
      "2023-12-04 20:42:11 INFO     Modified label to ID: {'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-LOC': 3, 'I-LOC': 4, 'B-ANIM': 5, 'I-ANIM': 6, 'B-DIS': 7, 'I-DIS': 8}\n",
      "2023-12-04 20:42:11 INFO     Modified ID to label: {0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-LOC', 4: 'I-LOC', 5: 'B-ANIM', 6: 'I-ANIM', 7: 'B-DIS', 8: 'I-DIS'}\n",
      "2023-12-04 20:42:11 INFO     Adding Sequence(ClassLabel) feature to dataset to make it usable with the `TokenClassificationEvaluator` from `evaluation`.\n",
      "Read more: https://huggingface.co/docs/evaluate/v0.4.0/en/package_reference/evaluator_classes\n"
     ]
    }
   ],
   "source": [
    "system = PrepSystem(\n",
    "        labels=tagset,\n",
    "        pretrained_model_checkpoint=pretrained_model_checkpoint,\n",
    "        dataset_batch_size=16,\n",
    "        filter_tagset=filter_tagset,\n",
    "        language=\"en\",\n",
    "        # set split_filter to None to load the entire dataset\n",
    "        split_filter=None,  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 262560\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 32820\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags'],\n",
       "        num_rows: 32908\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:42:11.795169: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:42:11.795337: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:42:11.795406: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:42:11.835951: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:42:11.836104: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:42:11.836179: I tensorflow/core/common_runtime/gpu/gpu_process_state.cc:236] Using CUDA malloc Async allocator for GPU: 0\n",
      "2023-12-04 20:42:11.836258: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2023-12-04 20:42:11.836322: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 3614 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4050 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n",
      "2023-12-04 20:42:11.996058: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFDistilBertForTokenClassification: ['vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing TFDistilBertForTokenClassification from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFDistilBertForTokenClassification from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights or buffers of the TF 2.0 model TFDistilBertForTokenClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_token_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  6921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66369801 (253.18 MB)\n",
      "Trainable params: 66369801 (253.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "system.get_model()\n",
    "system.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 2023, 2003, 2005, 2043, 2017, 2131, 3236, 1999, 1037, 3637, 1011, 11421, 1998, 1996, 3712, 2003, 2041, 1997, 2344, 102]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'this',\n",
       " 'is',\n",
       " 'for',\n",
       " 'when',\n",
       " 'you',\n",
       " 'get',\n",
       " 'caught',\n",
       " 'in',\n",
       " 'a',\n",
       " 'sleep',\n",
       " '-',\n",
       " 'riot',\n",
       " 'and',\n",
       " 'the',\n",
       " 'sky',\n",
       " 'is',\n",
       " 'out',\n",
       " 'of',\n",
       " 'order',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.load_tokenizer()\n",
    "sentence = \"This is for when you get caught in a sleep-riot and the sky is out of order\"\n",
    "tokenized = system.tokenizer(sentence.split(\" \"), truncation=True,\n",
    "            is_split_into_words=True)\n",
    "print(tokenized[\"input_ids\"])\n",
    "system.tokenizer.convert_ids_to_tokens(tokenized[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a smaller subset of the dataset \n",
    "num_examples = 1000\n",
    "for ds in system.data_split:\n",
    "    system.dataset[ds] = system.dataset[ds].select(range(num_examples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d204564441f64b5ca7d8615015027771",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddea79380de84a3d8f1fb80245869504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17b34636364c41b590ae3b08978644ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 1000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.tokenize_dataset()\n",
    "system.tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and tokenized.\n",
      "Sample: {'tokens': ['Karl', 'Marx', \"'s\", 'writing', 'on', 'the', 'commodity', 'abstraction', 'recognizes', 'a', 'parallel', 'process', '.'], 'ner_tags': [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'input_ids': [101, 6382, 13518, 1005, 1055, 3015, 2006, 1996, 19502, 24504, 14600, 1037, 5903, 2832, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100]}\n",
      "Decoded: ['[CLS]', 'karl', 'marx', \"'\", 's', 'writing', 'on', 'the', 'commodity', 'abstraction', 'recognizes', 'a', 'parallel', 'process', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "sample = system.tokenized_dataset[\"train\"][randint(0, 200)]\n",
    "print(f\"Dataset loaded and tokenized.\\nSample: {sample}\")\n",
    "print(f\"Decoded: {system.tokenizer.convert_ids_to_tokens(sample['input_ids'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_distil_bert_for_token_classification\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " distilbert (TFDistilBertMa  multiple                  66362880  \n",
      " inLayer)                                                        \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        multiple                  0         \n",
      "                                                                 \n",
      " classifier (Dense)          multiple                  6921      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66369801 (253.18 MB)\n",
      "Trainable params: 66369801 (253.18 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-04 20:42:27 INFO     None\n",
      "2023-12-04 20:42:27 INFO     Early stopping with patience of 2\n",
      "2023-12-04 20:42:27 INFO     Storing model checkpoint at each epoch\n",
      "2023-12-04 20:42:27 INFO     Fitting model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62/62 [==============================] - ETA: 0s - loss: 0.7094"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snek/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "2023-12-04 20:42:49 INFO     \n",
      "2023-12-04 20:42:49 INFO     Entity: ANIM\n",
      "2023-12-04 20:42:49 INFO     precision \t 0.0\n",
      "2023-12-04 20:42:49 INFO     recall \t 0.0\n",
      "2023-12-04 20:42:49 INFO     f1 \t 0.0\n",
      "2023-12-04 20:42:49 INFO     \n",
      "2023-12-04 20:42:49 INFO     Entity: DIS\n",
      "2023-12-04 20:42:49 INFO     precision \t 0.0\n",
      "2023-12-04 20:42:49 INFO     recall \t 0.0\n",
      "2023-12-04 20:42:49 INFO     f1 \t 0.0\n",
      "2023-12-04 20:42:49 INFO     \n",
      "2023-12-04 20:42:49 INFO     Entity: LOC\n",
      "2023-12-04 20:42:49 INFO     precision \t 0.0\n",
      "2023-12-04 20:42:49 INFO     recall \t 0.0\n",
      "2023-12-04 20:42:49 INFO     f1 \t 0.0\n",
      "2023-12-04 20:42:49 INFO     \n",
      "2023-12-04 20:42:49 INFO     Entity: PER\n",
      "2023-12-04 20:42:49 INFO     precision \t 0.648\n",
      "2023-12-04 20:42:49 INFO     recall \t 0.5901639344262295\n",
      "2023-12-04 20:42:49 INFO     f1 \t 0.6177311725452812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to ./distilbert-base-uncased-finetuned-ner-my_experiment/checkpoint_01.model.h5\n",
      "62/62 [==============================] - 22s 266ms/step - loss: 0.7094 - val_loss: 0.3231 - precision: 0.6480 - recall: 0.2014 - f1: 0.3073 - accuracy: 0.9203\n"
     ]
    }
   ],
   "source": [
    "experiment_name = \"my_experiment\"\n",
    "train(\n",
    "        optimizer=optimizer,\n",
    "        system=system,\n",
    "        verbose=1,\n",
    "        epochs=1,\n",
    "        \n",
    "        # True to generate tensorboard logs\n",
    "        tensorboard_callback=False,\n",
    "\n",
    "        # True to push to hub (make sure you are logged in)\n",
    "        # False to store results locally\n",
    "        push_to_hub_callback=False,\n",
    "\n",
    "        # False to disable\n",
    "        early_stopping=True, \n",
    "        early_stopping_patience=2,\n",
    "        experiment_name=experiment_name,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
       " 'ner_tags': Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-LOC', 'I-LOC', 'B-ANIM', 'I-ANIM', 'B-DIS', 'I-DIS'], id=None), length=-1, id=None)}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system.dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62f74b9a7a434395aac8c0e95ddd20fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snek/rise-assignment-ner-finetune/.venv/lib/python3.10/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from evaluate import evaluator\n",
    "task_evaluator = evaluator(\"token-classification\")\n",
    "\n",
    "metric = \"seqeval\"\n",
    "\n",
    "results = task_evaluator.compute(\n",
    "    model_or_pipeline=system.model,\n",
    "    data=system.dataset[\"test\"],\n",
    "    tokenizer=system.tokenizer,\n",
    "    metric=metric,\n",
    "    device=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ANIM': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 105},\n",
       " 'DIS': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 47},\n",
       " 'LOC': {'precision': 0.0, 'recall': 0.0, 'f1': 0.0, 'number': 635},\n",
       " 'PER': {'precision': 0.7097457627118644,\n",
       "  'recall': 0.850253807106599,\n",
       "  'f1': 0.7736720554272517,\n",
       "  'number': 394},\n",
       " 'overall_precision': 0.7097457627118644,\n",
       " 'overall_recall': 0.283657917019475,\n",
       " 'overall_f1': 0.4053236539624924,\n",
       " 'overall_accuracy': 0.9186568244319004,\n",
       " 'total_time_in_seconds': 47.389511141000185,\n",
       " 'samples_per_second': 21.10171588444232,\n",
       " 'latency_in_seconds': 0.047389511141000186}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
